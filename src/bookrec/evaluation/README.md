# bookrec.evaluation

Ranking metrics used in offline evaluation:
- `precision_at_k`
- `recall_at_k`
- `average_precision` (AP)
- `ndcg_at_k`

Use these to compare models on held-out user interactions.
